#!/usr/bin/env python3
"""
NovelAI MCP Server
ä½¿ç”¨ novelai-python SDK å°è£… NovelAI å›¾åƒç”Ÿæˆ API ä¸º MCP å·¥å…·é›†ã€‚
æ”¯æŒ Vibe Transfer + Precise Referenceï¼ˆCharacter / Style / Character&Styleï¼‰
"""


import base64
import io
import json
import os
import random
import sys
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Annotated

import httpx
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP, Image
from mcp.types import TextContent, ImageContent
from PIL import Image as PILImage
from pydantic import SecretStr

from novelai_python import GenerateImageInfer, ApiCredential, ImageGenerateResp
from novelai_python.sdk.ai.generate_image import Character, Model, Sampler, UCPreset
from novelai_python.sdk.ai.generate_image.schema import CharacterPosition


# ---------------------------------------------------------------------------
# å…¨å±€å˜é‡ï¼ˆåœ¨ main() ä¸­åˆå§‹åŒ–ï¼‰
# ---------------------------------------------------------------------------

credential: ApiCredential | None = None
API_KEY: str | None = None
DEFAULT_SAVE_DIR: str = str(Path.home() / "Pictures" / "NovelAI")
SAVE_DIR: str = DEFAULT_SAVE_DIR

# ---------------------------------------------------------------------------
# FastMCP å®ä¾‹
# ---------------------------------------------------------------------------

mcp = FastMCP(
    "NovelAI",
    instructions="",  # åœ¨ main() ä¸­åŠ¨æ€è®¾ç½®
)

# ---------------------------------------------------------------------------
# è¾…åŠ©å‡½æ•°
# ---------------------------------------------------------------------------

MODEL_MAP = {
    "v4.5-full": Model.NAI_DIFFUSION_4_5_FULL,
    "v4.5-curated": Model.NAI_DIFFUSION_4_5_CURATED,
    "v4-full": Model.NAI_DIFFUSION_4_FULL,
    "v4-curated": Model.NAI_DIFFUSION_4_CURATED_PREVIEW,
    "v3": Model.NAI_DIFFUSION_3,
}

AVAILABLE_MODELS = ", ".join(MODEL_MAP.keys())

DANBOORU_CATEGORY_MAP = {
    0: "general",     # é€šç”¨æ ‡ç­¾ï¼ˆå§¿åŠ¿ã€æœè£…ã€åœºæ™¯ç­‰ï¼‰
    1: "artist",      # ç”»å¸ˆ
    3: "copyright",   # ç‰ˆæƒ/ä½œå“å
    4: "character",   # è§’è‰²å
    5: "meta",        # å…ƒæ•°æ®
}


def resolve_model(model_name: str) -> Model:
    """å°†ç”¨æˆ·å‹å¥½çš„æ¨¡å‹åç§°è§£æä¸º SDK æ¨¡å‹æšä¸¾"""
    key = model_name.lower().strip()
    if key in MODEL_MAP:
        return MODEL_MAP[key]
    try:
        return Model(key)
    except ValueError:
        raise ValueError(
            f"æœªçŸ¥æ¨¡å‹: '{model_name}'ã€‚å¯ç”¨æ¨¡å‹: {AVAILABLE_MODELS}"
        )


def parse_characters(characters: list[dict] | None) -> list[Character] | None:
    """å°†ç”¨æˆ·ä¼ å…¥çš„è§’è‰²åˆ—è¡¨è½¬æ¢ä¸º SDK çš„ Character å¯¹è±¡"""
    if not characters:
        return None
    result = []
    for char in characters:
        center = CharacterPosition(
            x=char.get("center_x", 0.5),
            y=char.get("center_y", 0.5),
        )
        result.append(
            Character(
                prompt=char["prompt"],
                uc=char.get("negative_prompt", ""),
                center=center,
            )
        )
    return result


def save_image(image_data: bytes, prefix: str = "nai") -> str:
    """ä¿å­˜å›¾ç‰‡åˆ° SAVE_DIR å¹¶è¿”å›è·¯å¾„"""
    save_dir = Path(SAVE_DIR)
    save_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}.png"
    filepath = save_dir / filename
    filepath.write_bytes(image_data)
    return str(filepath)


def load_reference_images(paths: list[str] | None) -> list[bytes] | None:
    """ä»æ–‡ä»¶è·¯å¾„åˆ—è¡¨è¯»å–å‚è€ƒå›¾ç‰‡ï¼Œè¿”å› bytes åˆ—è¡¨"""
    if not paths:
        return None
    result = []
    for p in paths:
        path = Path(p)
        if not path.exists():
            raise FileNotFoundError(f"å‚è€ƒå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {p}")
        data = path.read_bytes()
        print(f"ğŸ“‚ å·²è¯»å–å‚è€ƒå›¾: {p} ({len(data)} bytes)", file=sys.stderr)
        result.append(data)
    return result


# ---------------------------------------------------------------------------
# Precise Reference è¾…åŠ©å‡½æ•°
# ---------------------------------------------------------------------------

ACCEPTED_CR_SIZES = [(1024, 1536), (1536, 1024), (1472, 1472)]

REFERENCE_MODES = ["character", "style", "character&style"]


def letterbox_for_reference(image_path: str) -> str:
    """
    è¯»å–å›¾ç‰‡ â†’ é€‰æ‹©æœ€æ¥è¿‘å®½é«˜æ¯”çš„ç”»å¸ƒ â†’ letterbox å±…ä¸­ â†’ è¿”å› base64 ç¼–ç ã€‚
    Precise Reference è¦æ±‚å‚è€ƒå›¾ä¸º 1024x1536 / 1536x1024 / 1472x1472 ä¹‹ä¸€ã€‚
    """
    path = Path(image_path)
    if not path.exists():
        raise FileNotFoundError(f"Precise Reference å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")

    pil_img = PILImage.open(path).convert("RGB")
    w, h = pil_img.size

    # é€‰æ‹©å®½é«˜æ¯”æœ€æ¥è¿‘çš„ç”»å¸ƒ
    aspect = w / h
    canvas_w, canvas_h = min(ACCEPTED_CR_SIZES, key=lambda s: abs(s[0] / s[1] - aspect))

    # ç­‰æ¯”ç¼©æ”¾ + å±…ä¸­æ”¾åˆ°é»‘è‰²ç”»å¸ƒä¸Š
    scale = min(canvas_w / w, canvas_h / h)
    new_w, new_h = max(1, int(w * scale)), max(1, int(h * scale))
    resized = pil_img.resize((new_w, new_h), PILImage.LANCZOS)

    canvas = PILImage.new("RGB", (canvas_w, canvas_h), (0, 0, 0))
    offset = ((canvas_w - new_w) // 2, (canvas_h - new_h) // 2)
    canvas.paste(resized, offset)

    # ç¼–ç ä¸º base64 PNG
    buf = io.BytesIO()
    canvas.save(buf, format="PNG")
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

    print(f"ğŸ“ Precise Reference: {w}x{h} â†’ letterbox {canvas_w}x{canvas_h}", file=sys.stderr)
    return b64


def build_precise_reference_params(
    image_b64: str,
    mode: str = "character&style",
    fidelity: float = 1.0,
) -> dict:
    """
    æ„å»º director_reference_* å‚æ•°å­—å…¸ã€‚

    mode: "character" / "style" / "character&style"
    fidelity: 0.0~1.0ï¼Œæ˜ å°„ä¸º secondary_strength = 1.0 - fidelity
    """
    if mode not in REFERENCE_MODES:
        raise ValueError(f"æ— æ•ˆçš„ reference_mode: '{mode}'ï¼Œå¯é€‰: {REFERENCE_MODES}")
    fidelity = max(0.0, min(1.0, fidelity))

    return {
        "director_reference_images": [image_b64],
        "director_reference_descriptions": [{
            "use_coords": False,
            "use_order": False,
            "legacy_uc": False,
            "caption": {
                "base_caption": mode,
                "char_captions": [],
            },
        }],
        "director_reference_strength_values": [1.0],
        "director_reference_secondary_strength_values": [1.0 - fidelity],
        "director_reference_information_extracted": [1.0],
    }


def build_v4_prompt(prompt: str, negative_prompt: str, characters: list[dict] | None = None) -> tuple[dict, dict]:
    """æ„å»º v4_prompt å’Œ v4_negative_prompt ç»“æ„"""
    char_captions = []
    use_coords = False
    if characters:
        use_coords = True
        for char in characters:
            char_captions.append({
                "char_caption": char["prompt"],
                "centers": [{
                    "x": char.get("center_x", 0.5),
                    "y": char.get("center_y", 0.5),
                }],
            })

    v4_prompt = {
        "use_coords": use_coords,
        "use_order": False,
        "caption": {
            "base_caption": prompt,
            "char_captions": char_captions,
        },
    }
    v4_negative_prompt = {
        "use_coords": use_coords,
        "use_order": False,
        "caption": {
            "base_caption": negative_prompt or "lowres",
            "char_captions": [],
        },
    }
    return v4_prompt, v4_negative_prompt


def build_vibe_transfer_params(ref_images: list[bytes] | None, strength: float, info_extracted: float) -> dict:
    """æ„å»º Vibe Transfer å‚æ•°ï¼ˆreference_*_multiple ç³»åˆ—ï¼‰ï¼Œå›¾ç‰‡ resize åˆ° 448x448 + base64"""
    if not ref_images:
        return {
            "reference_image_multiple": [],
            "reference_strength_multiple": [],
            "reference_information_extracted_multiple": [],
        }
    b64_list = []
    for img_bytes in ref_images:
        pil = PILImage.open(io.BytesIO(img_bytes)).convert("RGBA")
        pil = pil.resize((448, 448), PILImage.LANCZOS)
        buf = io.BytesIO()
        pil.save(buf, format="PNG")
        b64_list.append(base64.b64encode(buf.getvalue()).decode("utf-8"))
    return {
        "reference_image_multiple": b64_list,
        "reference_strength_multiple": [strength] * len(b64_list),
        "reference_information_extracted_multiple": [info_extracted] * len(b64_list),
    }


async def generate_via_http(
    payload: dict,
) -> bytes:
    """
    ç»•è¿‡ SDK ç›´æ¥è°ƒç”¨ NovelAI HTTP APIã€‚
    è¿”å›ç”Ÿæˆå›¾ç‰‡çš„ bytesã€‚
    """
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }
    async with httpx.AsyncClient(timeout=180) as client:
        resp = await client.post(
            "https://image.novelai.net/ai/generate-image",
            headers=headers,
            content=json.dumps(payload).encode("utf-8"),
        )
        if resp.status_code >= 400:
            error_text = resp.text[:500]
            raise RuntimeError(
                f"NovelAI API é”™è¯¯ ({resp.status_code}): {error_text}"
            )

        # å“åº”æ˜¯ zip æ ¼å¼ï¼Œè§£å‹æå–å›¾ç‰‡
        with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:
            image_bytes = zf.read(zf.infolist()[0])
        return image_bytes


# ---------------------------------------------------------------------------
# MCP å·¥å…·
# ---------------------------------------------------------------------------


@mcp.tool()
async def generate_image(
    prompt: Annotated[str, "ä¸»æç¤ºè¯ã€‚æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€å’Œ NovelAI æ ‡ç­¾ã€‚ä¾‹å¦‚: 'masterpiece, best quality, 1girl, blue hair, school uniform'"],
    negative_prompt: Annotated[str, "è´Ÿé¢æç¤ºè¯ã€‚æè¿°ä½ ä¸æƒ³çœ‹åˆ°çš„å†…å®¹ã€‚ç•™ç©ºä½¿ç”¨é»˜è®¤å€¼ã€‚"] = "",
    model: Annotated[str, f"æ¨¡å‹é€‰æ‹©ã€‚å¯ç”¨: {AVAILABLE_MODELS}"] = "v4.5-full",
    width: Annotated[int, "å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰ï¼Œå¿…é¡»æ˜¯ 64 çš„å€æ•°ã€‚å¸¸ç”¨: 832ï¼ˆç«–å›¾ï¼‰ã€1216ï¼ˆæ¨ªå›¾ï¼‰ã€1024ï¼ˆæ–¹å›¾ï¼‰"] = 832,
    height: Annotated[int, "å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œå¿…é¡»æ˜¯ 64 çš„å€æ•°ã€‚å¸¸ç”¨: 1216ï¼ˆç«–å›¾ï¼‰ã€832ï¼ˆæ¨ªå›¾ï¼‰ã€1024ï¼ˆæ–¹å›¾ï¼‰"] = 1216,
    characters: Annotated[
        list[dict] | None,
        "è§’è‰²æ•°ç»„ã€‚æ¯ä¸ªè§’è‰²æ˜¯ä¸€ä¸ª dictï¼ŒåŒ…å«: promptï¼ˆè§’è‰²æè¿°ï¼‰ã€negative_promptï¼ˆå¯é€‰ï¼‰ã€center_xï¼ˆæ°´å¹³ä½ç½® 0-0.9ï¼‰ã€center_yï¼ˆå‚ç›´ä½ç½® 0-0.9ï¼‰ã€‚å•äººåœºæ™¯ä¼  1 ä¸ªï¼Œå¤šäººä¼ å¤šä¸ªã€‚"
    ] = None,
    seed: Annotated[int | None, "éšæœºç§å­ã€‚ä¸å¡«åˆ™éšæœºç”Ÿæˆã€‚"] = None,
    quality_toggle: Annotated[bool, "æ˜¯å¦è‡ªåŠ¨æ·»åŠ è´¨é‡æ ‡ç­¾ï¼ˆæ¨èå¼€å¯ï¼‰"] = True,
    variety_boost: Annotated[bool, "å¤šæ ·æ€§å¢å¼ºï¼ˆVariety Boostï¼‰ï¼Œæ”¹å–„æ ·æœ¬å¤šæ ·æ€§"] = True,
    reference_image_paths: Annotated[
        list[str] | None,
        "ã€Vibe Transferã€‘å‚è€ƒå›¾ç‰‡çš„æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨ï¼ˆæœ€å¤š 16 å¼ ï¼‰ã€‚å…è´¹ï¼ˆOpusï¼‰ï¼ŒåŸºäºé£æ ¼è¿ç§»ä¿æŒè§’è‰²å¤§è‡´å¤–è§‚ã€‚é€‚åˆè½»é‡çº§è§’è‰²ä¸€è‡´æ€§ã€‚å¯ä¸ Precise Reference åŒæ—¶ä½¿ç”¨ã€‚"
    ] = None,
    reference_strength: Annotated[
        float,
        "ã€Vibe Transferã€‘å‚è€ƒå›¾å¼ºåº¦ 0.0-1.0ã€‚æ¨è 0.4-0.6ã€‚"
    ] = 0.6,
    reference_information_extracted: Annotated[
        float,
        "ã€Vibe Transferã€‘ä¿¡æ¯æå–é‡ 0.0-1.0ã€‚æ¨è 0.8-1.0ã€‚"
    ] = 1.0,
    precise_reference_image_path: Annotated[
        str | None,
        "ã€Precise Referenceã€‘å‚è€ƒå›¾ç‰‡çš„æ–‡ä»¶ç»å¯¹è·¯å¾„ï¼ˆå•å¼ ï¼‰ã€‚æ¶ˆè€— Anlasã€‚åŸºäºä¸“ç”¨æ¨¡å‹ç²¾ç¡®å¤åˆ¶è§’è‰²èº«ä»½/ç”»é£ã€‚æ•ˆæœè¿œä¼˜äº Vibe Transferï¼Œé€‚åˆéœ€è¦ä¸¥æ ¼è§’è‰²ä¸€è‡´æ€§çš„åœºæ™¯ã€‚å›¾ç‰‡ä¼šè‡ªåŠ¨ letterbox åˆ°åˆé€‚åˆ†è¾¨ç‡ã€‚"
    ] = None,
    precise_reference_mode: Annotated[
        str,
        "ã€Precise Referenceã€‘å‚è€ƒæ¨¡å¼ã€‚'character'=ä»…å¤åˆ¶è§’è‰²èº«ä»½ï¼ˆæ¢è£…/æ¢èƒŒæ™¯æ—¶ç”¨ï¼‰ï¼›'style'=ä»…å¤åˆ¶ç”»é£ï¼›'character&style'=åŒæ—¶å¤åˆ¶è§’è‰²å’Œç”»é£ï¼ˆæ¨èï¼‰ã€‚"
    ] = "character&style",
    precise_reference_fidelity: Annotated[
        float,
        "ã€Precise Referenceã€‘ä¿çœŸåº¦ 0.0-1.0ã€‚1.0=æœ€ä¸¥æ ¼åŒ¹é…å‚è€ƒå›¾ï¼Œ0.0=æœ€è‡ªç”±ã€‚æ¨è 0.8-1.0ã€‚"
    ] = 1.0,
) -> Image:
    """
    ä½¿ç”¨ NovelAI ç”Ÿæˆå›¾ç‰‡ï¼ˆæ–‡ç”Ÿå›¾ï¼‰ã€‚

    è°ƒç”¨æ—¶æœºï¼š
    - ç”¨æˆ·è¦æ±‚ã€Œç”»ã€ã€Œç”Ÿæˆã€ã€Œåˆ›å»ºã€å›¾ç‰‡/å›¾åƒæ—¶
    - ç”¨æˆ·æè¿°æƒ³è¦çœ‹åˆ°çš„è§†è§‰å†…å®¹æ—¶
    - ç¤ºä¾‹ï¼šã€Œç”»ä¸€åªçŒ«ã€ã€Œç”Ÿæˆä¸€ä¸ªè“å‘åŠ¨æ¼«å¥³å­©ã€ã€Œå¸®æˆ‘åšå¼ å›¾ã€

    æ”¯æŒå•äººå’Œå¤šäººåœºæ™¯ï¼Œé€šè¿‡ characters å‚æ•°å®šä¹‰è§’è‰²ä½ç½®ã€‚

    ä¸¤ç§è§’è‰²ä¸€è‡´æ€§æ–¹æ¡ˆï¼ˆå¯åŒæ—¶ä½¿ç”¨ï¼‰ï¼š
    1. Vibe Transferï¼ˆreference_image_pathsï¼‰ï¼šå…è´¹ï¼Œé£æ ¼è¿ç§»ï¼Œé€‚åˆå¤§è‡´ä¿æŒè§’è‰²å¤–è§‚
    2. Precise Referenceï¼ˆprecise_reference_image_pathï¼‰ï¼šæ¶ˆè€— Anlasï¼Œç²¾ç¡®å¤åˆ¶è§’è‰²èº«ä»½/ç”»é£
       - mode="character": ä»…å¤åˆ¶è§’è‰²ï¼ˆé€‚åˆæ¢è£…ã€æ¢èƒŒæ™¯ï¼‰
       - mode="style": ä»…å¤åˆ¶ç”»é£ï¼ˆé€‚åˆé£æ ¼è¿ç§»ï¼‰
       - mode="character&style": åŒæ—¶å¤åˆ¶è§’è‰²å’Œç”»é£ï¼ˆæ¨èï¼‰
    """
    resolved_model = resolve_model(model)
    actual_seed = seed if seed is not None else random.randint(0, 9999999999)

    # ===== åˆ¤æ–­æ˜¯å¦éœ€è¦èµ° HTTP ç›´è°ƒè·¯å¾„ =====
    if precise_reference_image_path:
        # === Precise Reference è·¯å¾„ï¼šç»•è¿‡ SDK ç›´æ¥å‘ HTTP ===
        print(f"ğŸ¯ Precise Reference æ¨¡å¼: {precise_reference_mode}, ä¿çœŸåº¦={precise_reference_fidelity}", file=sys.stderr)

        # 1. å‡†å¤‡å‚è€ƒå›¾
        ref_b64 = letterbox_for_reference(precise_reference_image_path)
        pr_params = build_precise_reference_params(ref_b64, precise_reference_mode, precise_reference_fidelity)

        # 2. å‡†å¤‡ Vibe Transferï¼ˆå¯æ··åˆä½¿ç”¨ï¼‰
        ref_images = load_reference_images(reference_image_paths)
        vt_params = build_vibe_transfer_params(ref_images, reference_strength, reference_information_extracted)
        if ref_images:
            print(f"ğŸ”— + Vibe Transfer: {len(ref_images)} å¼ å‚è€ƒå›¾", file=sys.stderr)

        # 3. æ„å»º v4_prompt
        v4_prompt, v4_neg = build_v4_prompt(prompt, negative_prompt, characters)

        # 4. æ„å»ºå®Œæ•´ payload
        params = {
            "params_version": 1,
            "width": width,
            "height": height,
            "scale": 5.0,
            "sampler": "k_euler",
            "steps": 28,
            "seed": actual_seed,
            "n_samples": 1,
            "ucPreset": 3,
            "qualityToggle": quality_toggle,
            "sm": False,
            "sm_dyn": False,
            "dynamic_thresholding": False,
            "controlnet_strength": 1.0,
            "legacy": False,
            "add_original_image": False,
            "cfg_rescale": 0.0,
            "noise_schedule": "native",
            "legacy_v3_extend": False,
            "uncond_scale": 1.0,
            "negative_prompt": negative_prompt or "lowres",
            "prompt": prompt,
            "extra_noise_seed": actual_seed,
            "v4_prompt": v4_prompt,
            "v4_negative_prompt": v4_neg,
            **vt_params,
            **pr_params,
        }

        if variety_boost:
            # skip_cfg_above_sigma è®¡ç®— (æ¥è‡ª ComfyUI é€†å‘)
            params["skip_cfg_above_sigma"] = round((width * height / 1011712) ** 0.5 * 19)

        payload = {
            "input": prompt,
            "model": resolved_model.value,
            "action": "generate",
            "parameters": params,
        }

        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾ç‰‡... (æ¨¡å‹: {resolved_model.value}, Precise Reference)", file=sys.stderr)
        image_data = await generate_via_http(payload)
    else:
        # === åŸæœ‰ SDK è·¯å¾„ ===
        character_list = parse_characters(characters)

        ref_images = load_reference_images(reference_image_paths)
        ref_kwargs = {}
        if ref_images:
            ref_kwargs["reference_image_multiple"] = ref_images
            ref_kwargs["reference_strength_multiple"] = [reference_strength] * len(ref_images)
            ref_kwargs["reference_information_extracted_multiple"] = [reference_information_extracted] * len(ref_images)
            print(f"ğŸ”— Vibe Transfer: {len(ref_images)} å¼ å‚è€ƒå›¾, å¼ºåº¦={reference_strength}", file=sys.stderr)

        gen = GenerateImageInfer.build_generate(
            prompt=prompt,
            model=resolved_model,
            negative_prompt=negative_prompt if negative_prompt else None,
            width=width,
            height=height,
            character_prompts=character_list,
            seed=actual_seed,
            qualityToggle=quality_toggle,
            variety_boost=variety_boost,
            ucPreset=UCPreset.TYPE0,
            **ref_kwargs,
        )

        try:
            cost = gen.calculate_cost(is_opus=True)
            if cost > 0:
                print(f"ğŸ’° é¢„è®¡æ¶ˆè€— {cost} Anlas", file=sys.stderr)
        except Exception:
            pass

        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾ç‰‡... (æ¨¡å‹: {resolved_model.value})", file=sys.stderr)
        resp: ImageGenerateResp = await gen.request(session=credential)
        _, image_data = resp.files[0]

    saved_path = save_image(image_data, prefix="gen")
    print(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {saved_path}", file=sys.stderr)

    return [
        TextContent(type="text", text=f"å›¾ç‰‡å·²ä¿å­˜åˆ°: {saved_path}"),
        ImageContent(type="image", data=base64.b64encode(image_data).decode("utf-8"), mimeType="image/png"),
    ]


@mcp.tool()
async def img2img(
    prompt: Annotated[str, "æç¤ºè¯ã€‚æè¿°ä½ æƒ³è¦åœ¨å›¾ç‰‡åŸºç¡€ä¸Šç”Ÿæˆçš„å†…å®¹ã€‚"],
    image_path: Annotated[str, "è¾“å…¥å›¾ç‰‡çš„æ–‡ä»¶ç»å¯¹è·¯å¾„ã€‚ä¾‹å¦‚: '/Users/xxx/Pictures/NovelAI/gen_20260217_100218.png'"],
    strength: Annotated[float, "å˜åŒ–å¼ºåº¦ï¼Œ0.01-0.99ã€‚è¶Šå¤§å˜åŒ–è¶Šå¤šã€‚"] = 0.7,
    noise: Annotated[float, "æ·»åŠ å™ªå£°é‡ï¼Œ0-0.99ã€‚"] = 0.0,
    negative_prompt: Annotated[str, "è´Ÿé¢æç¤ºè¯ã€‚"] = "",
    model: Annotated[str, f"æ¨¡å‹é€‰æ‹©ã€‚å¯ç”¨: {AVAILABLE_MODELS}"] = "v4.5-full",
    width: Annotated[int, "è¾“å‡ºå®½åº¦ï¼Œå¿…é¡»æ˜¯ 64 çš„å€æ•°ã€‚"] = 832,
    height: Annotated[int, "è¾“å‡ºé«˜åº¦ï¼Œå¿…é¡»æ˜¯ 64 çš„å€æ•°ã€‚"] = 1216,
    seed: Annotated[int | None, "éšæœºç§å­ã€‚"] = None,
    reference_image_paths: Annotated[
        list[str] | None,
        "ã€Vibe Transferã€‘å‚è€ƒå›¾ç‰‡çš„æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨ï¼ˆæœ€å¤š 16 å¼ ï¼‰ã€‚å…è´¹ï¼ˆOpusï¼‰ï¼Œé£æ ¼è¿ç§»ã€‚"
    ] = None,
    reference_strength: Annotated[
        float,
        "ã€Vibe Transferã€‘å‚è€ƒå›¾å¼ºåº¦ 0.0-1.0ã€‚æ¨è 0.4-0.6ã€‚"
    ] = 0.6,
    reference_information_extracted: Annotated[
        float,
        "ã€Vibe Transferã€‘ä¿¡æ¯æå–é‡ 0.0-1.0ã€‚æ¨è 0.8-1.0ã€‚"
    ] = 1.0,
    precise_reference_image_path: Annotated[
        str | None,
        "ã€Precise Referenceã€‘å‚è€ƒå›¾ç‰‡çš„æ–‡ä»¶ç»å¯¹è·¯å¾„ï¼ˆå•å¼ ï¼‰ã€‚æ¶ˆè€— Anlasã€‚ç²¾ç¡®å¤åˆ¶è§’è‰²èº«ä»½/ç”»é£ã€‚"
    ] = None,
    precise_reference_mode: Annotated[
        str,
        "ã€Precise Referenceã€‘å‚è€ƒæ¨¡å¼ã€‚'character' / 'style' / 'character&style'ï¼ˆæ¨èï¼‰ã€‚"
    ] = "character&style",
    precise_reference_fidelity: Annotated[
        float,
        "ã€Precise Referenceã€‘ä¿çœŸåº¦ 0.0-1.0ã€‚1.0=æœ€ä¸¥æ ¼åŒ¹é…ã€‚æ¨è 0.8-1.0ã€‚"
    ] = 1.0,
) -> Image:
    """
    åŸºäºå·²æœ‰å›¾ç‰‡ç”Ÿæˆæ–°å›¾ï¼ˆå›¾ç”Ÿå›¾ / img2imgï¼‰ã€‚

    è°ƒç”¨æ—¶æœºï¼š
    - ç”¨æˆ·æƒ³ä¿®æ”¹æˆ–å˜æ¢ç°æœ‰å›¾ç‰‡æ—¶
    - ç”¨æˆ·æä¾›äº†ä¸€å¼ å‚è€ƒå›¾å¹¶è¦æ±‚åœ¨æ­¤åŸºç¡€ä¸Šä¿®æ”¹

    æ”¯æŒ Vibe Transfer + Precise Referenceï¼ˆå¯åŒæ—¶ä½¿ç”¨ï¼‰ã€‚
    """
    resolved_model = resolve_model(model)
    actual_seed = seed if seed is not None else random.randint(0, 9999999999)

    path = Path(image_path)
    if not path.exists():
        raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
    image_bytes = path.read_bytes()
    print(f"ğŸ“‚ å·²è¯»å–å›¾ç‰‡: {image_path} ({len(image_bytes)} bytes)", file=sys.stderr)

    if precise_reference_image_path:
        # === Precise Reference è·¯å¾„ï¼šç»•è¿‡ SDK ===
        print(f"ğŸ¯ Precise Reference æ¨¡å¼: {precise_reference_mode}, ä¿çœŸåº¦={precise_reference_fidelity}", file=sys.stderr)

        ref_b64 = letterbox_for_reference(precise_reference_image_path)
        pr_params = build_precise_reference_params(ref_b64, precise_reference_mode, precise_reference_fidelity)

        ref_images = load_reference_images(reference_image_paths)
        vt_params = build_vibe_transfer_params(ref_images, reference_strength, reference_information_extracted)
        if ref_images:
            print(f"ğŸ”— + Vibe Transfer: {len(ref_images)} å¼ å‚è€ƒå›¾", file=sys.stderr)

        # å°†æºå›¾ç‰‡ resize + base64
        src_pil = PILImage.open(io.BytesIO(image_bytes)).convert("RGB")
        src_pil = src_pil.resize((width, height), PILImage.LANCZOS)
        src_buf = io.BytesIO()
        src_pil.save(src_buf, format="PNG")
        src_b64 = base64.b64encode(src_buf.getvalue()).decode("utf-8")

        v4_prompt, v4_neg = build_v4_prompt(prompt, negative_prompt)

        params = {
            "params_version": 1,
            "width": width,
            "height": height,
            "scale": 5.0,
            "sampler": "k_euler",
            "steps": 28,
            "seed": actual_seed,
            "n_samples": 1,
            "ucPreset": 3,
            "qualityToggle": True,
            "sm": False,
            "sm_dyn": False,
            "dynamic_thresholding": False,
            "controlnet_strength": 1.0,
            "legacy": False,
            "add_original_image": False,
            "cfg_rescale": 0.0,
            "noise_schedule": "native",
            "legacy_v3_extend": False,
            "uncond_scale": 1.0,
            "negative_prompt": negative_prompt or "lowres",
            "prompt": prompt,
            "extra_noise_seed": actual_seed,
            "image": src_b64,
            "strength": strength,
            "noise": noise,
            "v4_prompt": v4_prompt,
            "v4_negative_prompt": v4_neg,
            **vt_params,
            **pr_params,
        }

        payload = {
            "input": prompt,
            "model": resolved_model.value,
            "action": "img2img",
            "parameters": params,
        }

        print(f"ğŸ–Œï¸ æ­£åœ¨è¿›è¡Œå›¾ç”Ÿå›¾... (å¼ºåº¦: {strength}, Precise Reference)", file=sys.stderr)
        image_data = await generate_via_http(payload)
    else:
        # === åŸæœ‰ SDK è·¯å¾„ ===
        ref_images = load_reference_images(reference_image_paths)
        ref_kwargs = {}
        if ref_images:
            ref_kwargs["reference_image_multiple"] = ref_images
            ref_kwargs["reference_strength_multiple"] = [reference_strength] * len(ref_images)
            ref_kwargs["reference_information_extracted_multiple"] = [reference_information_extracted] * len(ref_images)
            print(f"ğŸ”— Vibe Transfer: {len(ref_images)} å¼ å‚è€ƒå›¾, å¼ºåº¦={reference_strength}", file=sys.stderr)

        gen = GenerateImageInfer.build_img2img(
            prompt=prompt,
            model=resolved_model,
            image=image_bytes,
            strength=strength,
            noise=noise,
            negative_prompt=negative_prompt if negative_prompt else None,
            width=width,
            height=height,
            seed=actual_seed,
            ucPreset=UCPreset.TYPE0,
            **ref_kwargs,
        )

        print(f"ğŸ–Œï¸ æ­£åœ¨è¿›è¡Œå›¾ç”Ÿå›¾... (å¼ºåº¦: {strength})", file=sys.stderr)
        resp: ImageGenerateResp = await gen.request(session=credential)
        _, image_data = resp.files[0]

    saved_path = save_image(image_data, prefix="i2i")
    print(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {saved_path}", file=sys.stderr)

    return [
        TextContent(type="text", text=f"å›¾ç‰‡å·²ä¿å­˜åˆ°: {saved_path}"),
        ImageContent(type="image", data=base64.b64encode(image_data).decode("utf-8"), mimeType="image/png"),
    ]


@mcp.tool()
async def suggest_tags(
    query: Annotated[str, "æœç´¢å…³é”®è¯ã€‚å¯ä»¥æ˜¯æ ‡ç­¾ç‰‡æ®µï¼ˆå¦‚ 'blue_h'ï¼‰æˆ–æ¦‚å¿µå…³é”®è¯ï¼ˆå¦‚ 'spread'ï¼‰ã€‚æ”¯æŒä¸‹åˆ’çº¿å’Œç©ºæ ¼ã€‚"],
    limit: Annotated[int, "è¿”å›ç»“æœæ•°é‡ä¸Šé™ï¼Œé»˜è®¤ 20ã€‚"] = 20,
) -> list[dict]:
    """
    æœç´¢ Danbooru æ ‡ç­¾ï¼Œç”¨äºæ„å»º NovelAI å›¾ç‰‡ç”Ÿæˆçš„ promptã€‚

    NovelAI ä½¿ç”¨ Danbooru æ ‡ç­¾ä½“ç³»ï¼Œç”¨ç²¾ç¡®æ ‡ç­¾æ•ˆæœè¿œå¥½äºè‡ªç„¶è¯­è¨€æè¿°ã€‚
    åœ¨æ„å»º prompt å‰ï¼Œæ¨èå¯¹æ¯ä¸ªæ¦‚å¿µéƒ½è°ƒç”¨æ­¤å·¥å…·æŸ¥è¯¢ç²¾ç¡®æ ‡ç­¾ã€‚

    ä½¿ç”¨å»ºè®®ï¼š
    - å°†ç”¨æˆ·æè¿°æ‹†è§£ä¸ºå¤šä¸ªç‹¬ç«‹æ¦‚å¿µï¼Œé€ä¸ªæŸ¥è¯¢
    - ä¾‹å¦‚ã€Œè“å‘å¥³å­©Må­—å¼€è…¿ã€â†’ åˆ†åˆ«æŸ¥ 'blue_hair'ã€'girl'ã€'m_leg'
    - post_count è¶Šé«˜ï¼Œè¡¨ç¤º NovelAI å¯¹è¯¥æ ‡ç­¾è¶Šç†Ÿæ‚‰ï¼Œç”Ÿæˆæ•ˆæœè¶Šå¥½
    - ä¼˜å…ˆé€‰æ‹© post_count > 1000 çš„æ ‡ç­¾

    è¿”å›å­—æ®µï¼š
    - tag: æ ‡ç­¾åï¼ˆç›´æ¥ç”¨äº NovelAI promptï¼‰
    - label: äººç±»å¯è¯»åç§°
    - category: æ ‡ç­¾åˆ†ç±»ï¼ˆgeneral=é€šç”¨, character=è§’è‰², copyright=ä½œå“, artist=ç”»å¸ˆ, meta=å…ƒæ•°æ®ï¼‰
    - post_count: ä½¿ç”¨æ¬¡æ•°ï¼ˆè¶Šé«˜ AI è¶Šç†Ÿæ‚‰ï¼‰
    """
    import httpx

    print(f"ğŸ” æ­£åœ¨æœç´¢ Danbooru æ ‡ç­¾: '{query}'", file=sys.stderr)

    async with httpx.AsyncClient(headers={"User-Agent": "NovelAI-MCP/1.0"}) as client:
        resp = await client.get(
            "https://danbooru.donmai.us/autocomplete.json",
            params={
                "search[query]": query,
                "search[type]": "tag_query",
                "limit": min(limit, 20),
            },
            timeout=10,
        )
        resp.raise_for_status()
        data = resp.json()

    results = []
    for item in data:
        tag_info = item.get("tag", {})
        category_id = item.get("category", tag_info.get("category", 0))
        results.append({
            "tag": item.get("value", tag_info.get("name", "")),
            "label": item.get("label", ""),
            "category": DANBOORU_CATEGORY_MAP.get(category_id, f"unknown({category_id})"),
            "post_count": item.get("post_count", tag_info.get("post_count", 0)),
        })

    print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªæ ‡ç­¾", file=sys.stderr)
    return results


@mcp.tool()
async def check_subscription() -> dict:
    """
    æŸ¥è¯¢ NovelAI è´¦æˆ·çš„è®¢é˜…çŠ¶æ€ã€‚

    è¿”å›å½“å‰è®¢é˜…ç­‰çº§ã€Anlas ä½™é¢ç­‰ä¿¡æ¯ã€‚
    åœ¨ç”Ÿæˆå›¾ç‰‡å‰è°ƒç”¨æ­¤å·¥å…·å¯ä»¥ç¡®è®¤è´¦æˆ·çŠ¶æ€ã€‚
    """
    import httpx

    headers = {"Authorization": f"Bearer {API_KEY}"}

    async with httpx.AsyncClient() as client:
        sub_resp = await client.get(
            "https://api.novelai.net/user/subscription",
            headers=headers,
        )
        sub_resp.raise_for_status()
        subscription = sub_resp.json()

        try:
            priority_resp = await client.get(
                "https://api.novelai.net/user/priority",
                headers=headers,
            )
            priority_resp.raise_for_status()
            priority = priority_resp.json()
        except Exception:
            priority = None

    tier_names = {0: "Free", 1: "Tablet", 2: "Scroll", 3: "Opus"}
    tier = subscription.get("tier", 0)

    result = {
        "tier": tier_names.get(tier, f"Unknown({tier})"),
        "active": subscription.get("active", False),
        "expiresAt": subscription.get("expiresAt"),
    }

    if priority:
        result["anlas"] = priority.get("maxPriorityActions", 0)

    return result


# ---------------------------------------------------------------------------
# å…¥å£
# ---------------------------------------------------------------------------


def main():
    """CLI å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(
        description="NovelAI MCP Server - AI å›¾åƒç”Ÿæˆå·¥å…·é›†",
        epilog="ç¤ºä¾‹: NOVELAI_API_KEY=pst-xxx python server.py --transport streamable-http",
    )
    parser.add_argument(
        "--transport",
        choices=["stdio", "streamable-http", "sse"],
        default="stdio",
        help="ä¼ è¾“æ¨¡å¼ (é»˜è®¤: stdio)",
    )
    parser.add_argument(
        "--port",
        type=int,
        default=3000,
        help="HTTP æœåŠ¡ç«¯å£ (é»˜è®¤: 3000, ä»… HTTP æ¨¡å¼)",
    )
    parser.add_argument(
        "--save-dir",
        type=str,
        default=None,
        help=f"å›¾ç‰‡ä¿å­˜ç›®å½• (é»˜è®¤: {DEFAULT_SAVE_DIR})",
    )
    args = parser.parse_args()

    # åŠ è½½ç¯å¢ƒå˜é‡å¹¶éªŒè¯ API Key
    load_dotenv()

    global API_KEY, SAVE_DIR, credential
    API_KEY = os.getenv("NOVELAI_API_KEY")
    if not API_KEY:
        print("âŒ é”™è¯¯: éœ€è¦è®¾ç½® NOVELAI_API_KEY ç¯å¢ƒå˜é‡", file=sys.stderr)
        print("   ç¤ºä¾‹: NOVELAI_API_KEY=pst-xxx python server.py", file=sys.stderr)
        sys.exit(1)

    # ä¼˜å…ˆçº§: CLI --save-dir > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
    if args.save_dir:
        SAVE_DIR = args.save_dir
    elif os.getenv("NOVELAI_SAVE_DIR"):
        SAVE_DIR = os.getenv("NOVELAI_SAVE_DIR")
    # else: ä¿æŒé»˜è®¤å€¼ DEFAULT_SAVE_DIR

    credential = ApiCredential(api_token=SecretStr(API_KEY))

    # åŠ¨æ€è®¾ç½® MCP instructionsï¼ŒåŒ…å«ä¿å­˜è·¯å¾„ä¿¡æ¯
    mcp._mcp_server.instructions = f"""NovelAI å›¾åƒç”Ÿæˆ MCP æœåŠ¡å™¨ã€‚
æä¾›ä»¥ä¸‹å·¥å…·ï¼š
- generate_image: æ–‡ç”Ÿå›¾ï¼ˆæ”¯æŒå¤šè§’è‰²å®šä½ + Vibe Transfer + Precise Referenceï¼‰
- img2img: å›¾ç”Ÿå›¾ï¼ˆåŸºäºå·²æœ‰å›¾ç‰‡ç”Ÿæˆæ–°å›¾ + Vibe Transfer + Precise Referenceï¼‰
- suggest_tags: Danbooru æ ‡ç­¾æœç´¢ï¼ˆæ„å»º prompt å‰æ¨èä½¿ç”¨ï¼‰
- check_subscription: æŸ¥è¯¢è®¢é˜…çŠ¶æ€å’Œ Anlas ä½™é¢

ğŸ“ å›¾ç‰‡ä¿å­˜ç›®å½•: {SAVE_DIR}
æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡éƒ½ä¼šè‡ªåŠ¨ä¿å­˜åˆ°ä¸Šè¿°ç›®å½•ã€‚

æ¨èå·¥ä½œæµï¼š
1. å°†ç”¨æˆ·æè¿°æ‹†è§£ä¸ºå¤šä¸ªæ¦‚å¿µ
2. å¯¹æ¯ä¸ªæ¦‚å¿µè°ƒç”¨ suggest_tags è·å–ç²¾ç¡® Danbooru æ ‡ç­¾
3. ç”¨è·å¾—çš„æ ‡ç­¾ç»„è£… prompt
4. è°ƒç”¨ generate_image ç”Ÿå›¾

===== è§’è‰²ä¸€è‡´æ€§ï¼šä¸¤ç§æ–¹æ¡ˆ =====

ã€æ–¹æ¡ˆ A: Vibe Transferã€‘å…è´¹ï¼ˆOpusï¼‰ï¼ŒåŸºäºé£æ ¼è¿ç§»ï¼Œé€‚åˆå¤§è‡´ä¿æŒè§’è‰²å¤–è§‚
- å‚æ•°: reference_image_paths + reference_strength
- ç‰¹ç‚¹: åé£æ ¼è¿ç§»ï¼Œè§’è‰²é¢éƒ¨/ç»†èŠ‚å¯èƒ½æœ‰åå·®
- reference_strength æ¨è 0.4-0.6ï¼ˆå¤ªé«˜ä¼šé”å®šå§¿åŠ¿å’Œæ„å›¾ï¼‰

ã€æ–¹æ¡ˆ B: Precise Referenceã€‘æ¶ˆè€— Anlasï¼ŒåŸºäºä¸“ç”¨æ¨¡å‹ï¼Œç²¾ç¡®å¤åˆ¶è§’è‰²èº«ä»½/ç”»é£
- å‚æ•°: precise_reference_image_path + precise_reference_mode + precise_reference_fidelity
- ä¸‰ç§æ¨¡å¼:
  - "character": ä»…å¤åˆ¶è§’è‰²èº«ä»½ï¼ˆæ¢è£…/æ¢èƒŒæ™¯æ—¶ç”¨ï¼‰
  - "style": ä»…å¤åˆ¶ç”»é£/è‰ºæœ¯é£æ ¼
  - "character&style": åŒæ—¶å¤åˆ¶è§’è‰²å’Œç”»é£ï¼ˆæ¨èé»˜è®¤é€‰æ‹©ï¼‰
- fidelity æ¨è 0.8-1.0ï¼ˆ1.0 æœ€ä¸¥æ ¼åŒ¹é…ï¼‰
- å‚è€ƒå›¾å»ºè®®: å…¨èº«ç«‹ç»˜ã€ä¸­æ€§å§¿åŠ¿ã€ç®€å•èƒŒæ™¯æ•ˆæœæœ€å¥½

ã€æ··åˆä½¿ç”¨ã€‘ä¸¤ç§æ–¹æ¡ˆå¯åŒæ—¶å¯ç”¨ï¼ŒVibe Transfer è´Ÿè´£æ•´ä½“é£æ ¼æ°›å›´ï¼ŒPrecise Reference è´Ÿè´£è§’è‰²ç²¾åº¦ã€‚

===== è§’è‰²ä¸€è‡´æ€§æ¨èæµç¨‹ =====
1. å…ˆç”¨ generate_image ç”Ÿæˆä¸€å¼ æ»¡æ„çš„è§’è‰²ç«‹ç»˜ï¼ˆå…¨èº«ã€ä¸­æ€§å§¿åŠ¿ã€ç®€å•èƒŒæ™¯ï¼‰
2. å†æ¬¡è°ƒç”¨ generate_image æ—¶ä¼ å…¥ precise_reference_image_path æŒ‡å‘è¯¥ç«‹ç»˜
3. prompt ä¸­æè¿°æ–°å§¿åŠ¿/åœºæ™¯ï¼Œè§’è‰²å¤–è§‚ç”± Precise Reference è‡ªåŠ¨ä¿æŒ
4. å¦‚éœ€è¿›ä¸€æ­¥å¾®è°ƒé£æ ¼ï¼Œå¯åŒæ—¶ä¼ å…¥ reference_image_paths ä½¿ç”¨ Vibe Transfer
"""

    print(f"ğŸš€ NovelAI MCP Server å¯åŠ¨ä¸­... (ä¼ è¾“: {args.transport})", file=sys.stderr)
    print(f"ğŸ“ å›¾ç‰‡ä¿å­˜ç›®å½•: {SAVE_DIR}", file=sys.stderr)

    if args.transport == "stdio":
        mcp.run(transport="stdio")
    elif args.transport == "streamable-http":
        mcp.run(transport="streamable-http", port=args.port)
    elif args.transport == "sse":
        mcp.run(transport="sse", port=args.port)


if __name__ == "__main__":
    main()
